{
  "base_dir": "llm/GGUF",
  "Qwen_model": {
    "Qwen3-4B-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-4B-GGUF",
      "repo_id": "Qwen/Qwen3-4B-GGUF",
      "model_files": [
        "Qwen3-4B-Q4_K_M.gguf",
        "Qwen3-4B-Q5_0.gguf",
        "Qwen3-4B-Q5_K_M.gguf",
        "Qwen3-4B-Q6_K.gguf",
        "Qwen3-4B-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192
      }
    },
    "Qwen3-4B-abliterated-GGUF": {
      "author": "Mungert",
      "repo_name": "Qwen3-4B-abliterated-GGUF",
      "repo_id": "Mungert/Qwen3-4B-abliterated-GGUF",
      "alt_repo_ids": [
        "mradermacher/Qwen3-4B-abliterated-GGUF"
      ],
      "model_files": [
        "Qwen3-4B-abliterated-iq2_m.gguf",
        "Qwen3-4B-abliterated-iq2_s.gguf",
        "Qwen3-4B-abliterated-iq2_xs.gguf",
        "Qwen3-4B-abliterated-iq2_xxs.gguf",
        "Qwen3-4B-abliterated-iq3_m.gguf",
        "Qwen3-4B-abliterated-iq3_s.gguf",
        "Qwen3-4B-abliterated-iq3_xs.gguf",
        "Qwen3-4B-abliterated-iq3_xxs.gguf",
        "Qwen3-4B-abliterated-iq4_nl.gguf",
        "Qwen3-4B-abliterated-iq4_xs.gguf",
        "Qwen3-4B-abliterated-q2_k_s.gguf",
        "Qwen3-4B-abliterated-q3_k_m.gguf",
        "Qwen3-4B-abliterated-q3_k_s.gguf",
        "Qwen3-4B-abliterated-q4_0.gguf",
        "Qwen3-4B-abliterated-q4_1.gguf",
        "Qwen3-4B-abliterated-q4_k_m.gguf",
        "Qwen3-4B-abliterated-q4_k_s.gguf",
        "Qwen3-4B-abliterated-q5_0.gguf",
        "Qwen3-4B-abliterated-q5_1.gguf",
        "Qwen3-4B-abliterated-q5_k_m.gguf",
        "Qwen3-4B-abliterated-q5_k_s.gguf",
        "Qwen3-4B-abliterated-q6_k_m.gguf",
        "Qwen3-4B-abliterated-q8_0.gguf",
        "Qwen3-4B-abliterated-bf16.gguf",
        "Qwen3-4B-abliterated-bf16_q8_0.gguf",
        "Qwen3-4B-abliterated-f16_q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192
      }
    },
   "Qwen3-VL-4B-Instruct-Abliterated-GGUF": {
      "author": "noctrex",
      "repo_name": "Qwen3-VL-4B-Instruct-Abliterated-GGUF",
      "repo_id": "noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF",
      "mmproj_file": "mmproj-F16.gguf",
      "model_files": [
        "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q5_K_M.gguf",
        "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q6_K.gguf",
        "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q8_0.gguf",
        "Huihui-Qwen3-VL-4B-Instruct-abliterated-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    }
  },
  "qwenVL_model": {
    "Qwen3-VL-4B-Instruct-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-4B-Instruct-GGUF",
      "repo_id": "Qwen/Qwen3-VL-4B-Instruct-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-4B-Instruct-F16.gguf",
      "model_files": [
        "Qwen3VL-4B-Instruct-Q4_K_M.gguf",
        "Qwen3VL-4B-Instruct-Q8_0.gguf",
        "Qwen3VL-4B-Instruct-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-4B-Instruct-Abliterated-GGUF": {
      "author": "noctrex",
      "repo_name": "Qwen3-VL-4B-Instruct-Abliterated-GGUF",
      "repo_id": "noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF",
      "mmproj_file": "mmproj-F16.gguf",
      "model_files": [
        "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q5_K_M.gguf",
        "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q6_K.gguf",
        "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q8_0.gguf",
        "Huihui-Qwen3-VL-4B-Instruct-abliterated-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-8B-Instruct-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-8B-Instruct-GGUF",
      "repo_id": "Qwen/Qwen3-VL-8B-Instruct-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-8B-Instruct-F16.gguf",
      "model_files": [
        "Qwen3VL-8B-Instruct-Q4_K_M.gguf",
        "Qwen3VL-8B-Instruct-Q8_0.gguf",
        "Qwen3VL-8B-Instruct-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-4B-Thinking-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-4B-Thinking-GGUF",
      "repo_id": "Qwen/Qwen3-VL-4B-Thinking-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-4B-Thinking-F16.gguf",
      "model_files": [
        "Qwen3VL-4B-Thinking-Q4_K_M.gguf",
        "Qwen3VL-4B-Thinking-Q8_0.gguf",
        "Qwen3VL-4B-Thinking-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-8B-Thinking-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-8B-Thinking-GGUF",
      "repo_id": "Qwen/Qwen3-VL-8B-Thinking-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-8B-Thinking-F16.gguf",
      "model_files": [
        "Qwen3VL-8B-Thinking-Q4_K_M.gguf",
        "Qwen3VL-8B-Thinking-Q8_0.gguf",
        "Qwen3VL-8B-Thinking-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    }
  }
}
